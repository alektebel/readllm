package com.readllm.app.llm

import android.content.Context
import com.google.mediapipe.tasks.genai.llminference.LlmInference
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import org.json.JSONArray
import org.json.JSONObject

/**
 * Text LLM Service for generating comprehension questions and evaluating answers
 * 
 * Uses MediaPipe LLM Inference API with Gemma 2B-IT (instruction-tuned) model
 * for on-device natural language understanding and generation.
 * 
 * Model Requirements:
 * - Download Gemma 2B-IT model (GPU int4 quantized version recommended)
 * - Place in: app/src/main/assets/models/gemma-2b-it-gpu-int4.bin
 * - Download from: https://www.kaggle.com/models/google/gemma/tfLite/
 * 
 * Alternative models you can use:
 * - Phi-2 (2.7B parameters)
 * - TinyLlama 1.1B
 * - Gemma 1.1-2B-IT
 */
class TextLLMService(private val context: Context) {
    
    private var llmInference: LlmInference? = null
    private var isInitialized = false
    
    companion object {
        private const val MODEL_PATH = "gemma-2b-it-gpu-int4.bin"
        private const val MAX_TOKENS = 512
        private const val TEMPERATURE = 0.7f
        private const val TOP_K = 40
    }
    
    /**
     * Data class for quiz questions generated by LLM
     */
    data class GeneratedQuestion(
        val question: String,
        val expectedAnswer: String,
        val type: String,
        val difficulty: Int
    )
    
    /**
     * Data class for answer evaluation result
     */
    data class EvaluationResult(
        val score: Int,  // 0-100
        val isCorrect: Boolean,
        val feedback: String
    )
    
    /**
     * Initialize the LLM model
     * Call this once at app startup or before first use
     */
    suspend fun initialize(): Boolean = withContext(Dispatchers.IO) {
        if (isInitialized) return@withContext true
        
        try {
            val options = LlmInference.LlmInferenceOptions.builder()
                .setModelPath(MODEL_PATH)
                .setMaxTokens(MAX_TOKENS)
                .setTemperature(TEMPERATURE)
                .setTopK(TOP_K)
                .build()
            
            llmInference = LlmInference.createFromOptions(context, options)
            isInitialized = true
            true
        } catch (e: Exception) {
            android.util.Log.e("TextLLMService", "Failed to initialize LLM: ${e.message}", e)
            isInitialized = false
            false
        }
    }
    
    /**
     * Generate 1-2 comprehension questions based on chapter content
     * 
     * @param chapterContent The full text of the chapter
     * @param chapterNumber The chapter number (for context)
     * @param numQuestions Number of questions to generate (1-2)
     * @return List of generated questions
     */
    suspend fun generateQuestions(
        chapterContent: String,
        chapterNumber: Int,
        numQuestions: Int = 1
    ): List<GeneratedQuestion> = withContext(Dispatchers.IO) {
        if (!isInitialized || llmInference == null) {
            android.util.Log.w("TextLLMService", "LLM not initialized, returning fallback questions")
            return@withContext getFallbackQuestions()
        }
        
        try {
            // Truncate content if too long (keep first 2000 chars for context)
            val truncatedContent = if (chapterContent.length > 2000) {
                chapterContent.take(2000) + "..."
            } else {
                chapterContent
            }
            
            val prompt = buildQuestionGenerationPrompt(truncatedContent, numQuestions)
            val response = llmInference?.generateResponse(prompt) ?: ""
            
            // Parse JSON response
            parseQuestionsFromResponse(response)
        } catch (e: Exception) {
            android.util.Log.e("TextLLMService", "Error generating questions: ${e.message}", e)
            getFallbackQuestions()
        }
    }
    
    /**
     * Evaluate user's answer against chapter content
     * 
     * @param userAnswer The answer provided by the user
     * @param question The question that was asked
     * @param chapterContent The chapter content for reference
     * @return Evaluation result with score and feedback
     */
    suspend fun evaluateAnswer(
        userAnswer: String,
        question: String,
        chapterContent: String
    ): EvaluationResult = withContext(Dispatchers.IO) {
        if (!isInitialized || llmInference == null) {
            android.util.Log.w("TextLLMService", "LLM not initialized, using fallback evaluation")
            return@withContext fallbackEvaluation(userAnswer)
        }
        
        try {
            // Truncate content if too long
            val truncatedContent = if (chapterContent.length > 1500) {
                chapterContent.take(1500) + "..."
            } else {
                chapterContent
            }
            
            val prompt = buildAnswerEvaluationPrompt(question, userAnswer, truncatedContent)
            val response = llmInference?.generateResponse(prompt) ?: ""
            
            // Parse evaluation from response
            parseEvaluationFromResponse(response)
        } catch (e: Exception) {
            android.util.Log.e("TextLLMService", "Error evaluating answer: ${e.message}", e)
            fallbackEvaluation(userAnswer)
        }
    }
    
    /**
     * Build prompt for question generation
     */
    private fun buildQuestionGenerationPrompt(content: String, numQuestions: Int): String {
        return """
You are a reading comprehension quiz generator. Based on the following text, generate $numQuestions comprehension question(s).

TEXT:
$content

Generate questions that test understanding of key concepts. Return your response as a JSON array with this exact format:
[
  {
    "question": "What is the main topic discussed in this chapter?",
    "expectedAnswer": "Brief expected answer",
    "type": "factual",
    "difficulty": 2
  }
]

Rules:
- Generate exactly $numQuestions question(s)
- Questions should be clear and answerable from the text
- Expected answers should be 1-3 sentences
- Type can be: "factual", "conceptual", or "inference"
- Difficulty: 1-5 (use 2-3 for most questions)
- Return ONLY the JSON array, no additional text

JSON:
        """.trimIndent()
    }
    
    /**
     * Build prompt for answer evaluation
     */
    private fun buildAnswerEvaluationPrompt(
        question: String,
        userAnswer: String,
        content: String
    ): String {
        return """
You are a reading comprehension evaluator. Grade the student's answer based on the chapter text.

CHAPTER TEXT:
$content

QUESTION:
$question

STUDENT'S ANSWER:
$userAnswer

Evaluate the answer and return a JSON object with this exact format:
{
  "score": 85,
  "isCorrect": true,
  "feedback": "Good answer! You correctly identified..."
}

Grading criteria:
- Score: 0-100 (0=completely wrong, 50=partial, 70+=mostly correct, 90+=excellent, 100=perfect)
- isCorrect: true if score >= 70, false otherwise
- feedback: 1-2 sentences explaining the score and referencing the chapter content

Be fair and encouraging. Give partial credit for reasonable attempts.
Return ONLY the JSON object, no additional text.

JSON:
        """.trimIndent()
    }
    
    /**
     * Parse questions from LLM JSON response
     */
    private fun parseQuestionsFromResponse(response: String): List<GeneratedQuestion> {
        return try {
            // Extract JSON array from response (in case there's extra text)
            val jsonStart = response.indexOf('[')
            val jsonEnd = response.lastIndexOf(']') + 1
            
            if (jsonStart == -1 || jsonEnd <= jsonStart) {
                android.util.Log.w("TextLLMService", "No JSON array found in response")
                return getFallbackQuestions()
            }
            
            val jsonString = response.substring(jsonStart, jsonEnd)
            val jsonArray = JSONArray(jsonString)
            
            val questions = mutableListOf<GeneratedQuestion>()
            for (i in 0 until jsonArray.length()) {
                val obj = jsonArray.getJSONObject(i)
                questions.add(
                    GeneratedQuestion(
                        question = obj.getString("question"),
                        expectedAnswer = obj.getString("expectedAnswer"),
                        type = obj.optString("type", "factual"),
                        difficulty = obj.optInt("difficulty", 2)
                    )
                )
            }
            
            if (questions.isEmpty()) getFallbackQuestions() else questions
        } catch (e: Exception) {
            android.util.Log.e("TextLLMService", "Error parsing questions JSON: ${e.message}", e)
            getFallbackQuestions()
        }
    }
    
    /**
     * Parse evaluation from LLM JSON response
     */
    private fun parseEvaluationFromResponse(response: String): EvaluationResult {
        return try {
            // Extract JSON object from response
            val jsonStart = response.indexOf('{')
            val jsonEnd = response.lastIndexOf('}') + 1
            
            if (jsonStart == -1 || jsonEnd <= jsonStart) {
                android.util.Log.w("TextLLMService", "No JSON object found in response")
                return fallbackEvaluation("")
            }
            
            val jsonString = response.substring(jsonStart, jsonEnd)
            val obj = JSONObject(jsonString)
            
            EvaluationResult(
                score = obj.optInt("score", 50),
                isCorrect = obj.optBoolean("isCorrect", false),
                feedback = obj.optString("feedback", "Your answer has been reviewed.")
            )
        } catch (e: Exception) {
            android.util.Log.e("TextLLMService", "Error parsing evaluation JSON: ${e.message}", e)
            fallbackEvaluation("")
        }
    }
    
    /**
     * Fallback questions when LLM is unavailable
     */
    private fun getFallbackQuestions(): List<GeneratedQuestion> {
        return listOf(
            GeneratedQuestion(
                question = "What is the main topic or key takeaway from this chapter? (Give a brief answer)",
                expectedAnswer = "The main concepts discussed in the chapter",
                type = "factual",
                difficulty = 2
            )
        )
    }
    
    /**
     * Fallback evaluation using simple keyword matching
     */
    private fun fallbackEvaluation(userAnswer: String): EvaluationResult {
        val wordCount = userAnswer.trim().split(Regex("\\s+")).size
        val score = when {
            wordCount == 0 -> 0
            wordCount < 3 -> 30
            wordCount < 10 -> 60
            else -> 75
        }
        
        return EvaluationResult(
            score = score,
            isCorrect = score >= 70,
            feedback = when {
                score >= 70 -> "Good answer! You've captured the key concepts."
                score >= 50 -> "Partial credit. Try to provide more detail from the chapter."
                else -> "Please provide a more detailed answer based on the chapter content."
            }
        )
    }
    
    /**
     * Cleanup resources
     */
    fun cleanup() {
        llmInference?.close()
        llmInference = null
        isInitialized = false
    }
}
